str(test)
test <- test[,-10]
str(test)
train <- train[:,-10]
train <- train[,-10]
mod <- lm(lpsa ~., data = train)
mod
print(mod)
summary(mod)
mod <- lm(lpsa ~ lcavol+lweight+lbph+svi, data = train)
summary(mod)
mod$residuals
sum(mod$residuals**2)
mean(mod$residuals**2)
mod$residuals**2
mean(mod$residuals**2)
library(caret)
mod <- train(lpsa ~ lcavol+lweight+lbph+svi, data = train, method = 'lm')
mod$finalModel
summary(mod)
mean((mean(train$lpsa) - predict(mod, train))**2)
mean((train$lpsa - predict(mod, train))**2)
mean(train$lpsa - predict(mod, train))
mean(train$lpsa - predict(mod, train))**2
mean((test$lpsa - predict(mod, test))**2)
confint(mod$coeff)
mod$coefnames
coefficients(mod)
coefficients(suumary(mod))
coefficients(summary(mod))
confint(coefficients(summary(mod)))
confint(summary(mod))
mod$coeff
mod$coefficients
coefficients(mod)
summary(mod)$coeff
confint(summary(mod)$coeff)
mod
mod <- lm(lpsa ~ lcavol+lweight+lbph+svi, data = train)
mod
mod$coefficients
confint(mod$coefficients)
confint.lm(mod)
confint(mod)
mean_lpsa = mean(train$lpsa)
mean_lpsa
mean((mean_lpsa - train$lpsa)**2)
mean((mean_lpsa - test$lpsa)**2)
mean((predict(mod,test) - test$lpsa)**2)
mod <- lm(lpsa + lcavol ~ lweight+lbph+svi, data = train)
mod
summary(mod)
mod$residuals
help("train")
help("createDataPartition")
str(prostate)
ss <- createDataPartition(prostate$lpsa, k = 10)
ss <- createDataPartition(prostate$lpsa, p=1.0, k = 10)
ss <- createDataPartition(prostate$lpsa, k = 5)
library(ISRL)
library(ISLR)
install.packages(ISLR)
data(wage)
install.packages(ISLR)
install.packages("ISLR")
data(wage)
library(ISLR)
data("Wage")
library(ggplot2)
library(caret)
Wage <- subset(Wage, select = -c(logwage))
inBuild <- createDataPartition(Wage$wage, p = 0.7, list = F)
validation <- Wage[-inBuild]
buildData <- Wage[inBuild,]
validation <- Wage[-inBuild,]
inTrain <- createDataPartition(buildData$wage, p=0.7, list = F)
training <- buildData[inTrain,]
testing <- buildData[-inTrain,]
dim(training)
mod1 <- train(wage~., method='glm', data = training)
mod2 <- train(wage~. methis = 'rf', data = training, trControl = trainControl(method = "cv"), number = 3)
mod2 <- train(wage~., method = 'rf', data = training, trControl = trainControl(method = "cv"), number = 3)
pred1 <- predict(mod1, data = training)
pred2 <- predict(mod2, data = training)
qplot(pred1,pred2, color = wage, data = training)
pred1 <- predict(mod1, data = testing)
pred2 <- predict(mod2, data = testing)
qplot(pred1,pred2, color = wage, data = testing)
str(testing)
qplot(pred1,pred2, colour = wage, data = testing)
mod2
mod1
pred2 <- predict(mod2, data = testing)
pred1 <- predict(mod1, data = testing)
qplot(pred1,pred2, colour = wage, data = testing)
pred1
dim(pred1)
class(pred1)
pred1[1]
testing <- buildData[-inTrain,]
pred1 <- predict(mod1, data = testing)
pred2 <- predict(mod2, data = testing)
qplot(pred1,pred2, colour = wage, data = testing)
class(pred1[1])
pred1[1][1]
pred1[1][2]
str(testing)
esting$wage
testing$wage
pred2 <- predict(mod2, testing)
pred1 <- predict(mod1, testing)
qplot(pred1,pred2, colour = wage, data = testing)
packageVersion("AppliedPredictiveModeling")
packageVersion("gbm")
install.packages(gbm)
install.packages("gbm")
install.packages("forecast")
install.packages("lmtest")
install.packages("lmtest")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
mod_rf <- train(y ~., data = vowel.train, method = 'rf')
mod_boost <- train(y ~., data = vowel.train, method = 'gbm')
mod_boost <- train(y ~., data = vowel.train, method = 'gbm', verbose = F)
mod_rf
str(vowel.train)
library(rattle)
install.packages("rattle")
library(rattle)
mod_rf$finalModel
predict(mod_rf, vowel.test)
mod_rf <- train(y ~., data = vowel.train, method = 'rf', prox=T)
table(predict(mod_rf, vowel.test), vowel.test$y)
help(acf)
mod_rf
table(predict(mod_rf, vowel.train), vowel.train$y)
table(predict(mod_rf, vowel.train$y), vowel.train$y)
table(predict(mod_rf, vowel.train), vowel.train$y)
mod_rf <- train(y ~., data = vowel.train, method = 'rf', prox=T)
table(predict(mod_rf, vowel.train), vowel.train$y)
table(predict(mod_rf, vowel.test), vowel.test$y)
(30+27+30+29+18+24+27+29+22+20+17)/legth(vowel.test$y)
(30+27+30+29+18+24+27+29+22+20+17)/length(vowel.test$y)
t <- table(predict(mod_rf, vowel.test), vowel.test$y)
t
diag(t)
sum(diag(t))
sum(diag(t))/sum(t)
sum(diag(t))/(11*11)
sum(diag(t))/sum(t)
mod_gbm
mod_boost
t2 <- table(predict(mod_boost, vowel.test), vowel.test$y)
t2
sum(diag(t2))/sum(t2)
t1
t
t3 <- table(predict(mod_rf, vowel.test), predict(mod_boost, vowel.test))
t3
sum(diag(t3))/sum(t3)
pred_rf <- predict(mod_rf, vowel.test$y)
pred_rf <- predict(mod_rf, vowel.test)
pred_boost <- predict(mod_boost, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_boost, vowel.test$y)
agree <- (pred_rf == pred_boost)
confusionMatrix(pred_boost[agree], volwel.test$y[agree])
confusionMatrix(pred_boost[agree], vowel.test$y[agree])
confusionMatrix(vowel.test$y[agree], pred_boost[agree])
library(gbm)
set.seed/3433
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
set.seed(62433)
rf <- train(diagnosis ~., data = training, method = 'rf', prox=T)
boost <- train(diagnosis ~., data = training, method = 'gbm', verbose = F)
lda <- train(diagnosis ~., data = training, method = 'lda')
pred_rf <- predict(rf, testing)
pred_boost <- predict(boost, testing)
pred_lda <- predict(lda, testing)
pred_data <- data.frame(rf = pred_rf, boost = pred_boost, lda = pred_lda, diagnosis = testing$diagnosis)
pred_data
comb <- train(diagnosis ~., data = pred_data, method = 'rf', prox=T)
pred_comb <- predict(comb, testing)
pred_comb <- predict(comb, pred_comb)
pred_comb <- predict(comb, comb)
pred_comb <- predict(comb, pred_data)
confusionMatrix(pred_comb, testing$diagnosis)
confusionMatrix(pred_rf, testing$diagnosis)
confusionMatrix(pred_boost, testing$diagnosis)
confusionMatrix(pred_lda, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
help(lasso)
library(lasso)
install.packages("lasso")
??lasso
library("e1071")
help(lasso)
lasso
library(caret)
lasso
lasso()
help(lasso)
help("train")
names(getModelInfo())
lasso <- train(CompressiveStrength ~. , data = training, method = 'lasso')
lasso <- train(CompressiveStrength ~. , data = training, method = 'lasso')
lasso
?plot.enet
class(lasso)
plot.enet(lasso)
plot(lasso)
str(training)
?plot.enet
plot(lasso, xvar = "L1norm")
plot(lasso, xvar = c("fraction", "penalty", "L1norm", "step"))
plot(lasso)
plot(lasso, xvar = L1nomr)
plot(lasso, xvar = L1norm)
plot(lasso, xvar = 'step')
plot(lasso, xvar = "step")
plot(lasso, xvar = "penalty")
lasso
lasso$finalModel
plot.enet(lasso$finalModel, xvars = "penalty")
plot(lasso$finalModel, xvars = "penalty")
plot.enet(lasso$finalModel)
install.packages("elasticnet")
install.packages("elasticnet")
plot.enet
plot.enet()
enet
help(plot.enet)
lasso$finalModel
plot.enet(lasso$finalModel)
library(elasticnet)
plot.enet(lasso$finalModel)
plot.enet(lasso$finalModel, xvar = "step")
plot.enet(lasso$finalModel, xvar = "penalyze")
plot.enet(lasso$finalModel, xvar = "L1norm")
plot.enet(lasso$finalModel, xvar = "fraction")
plot.enet(lasso$finalModel, xvar = "penalty")
cor(training$Cement, training$CompressiveStrength)
cor(training$Water, training$CompressiveStrength)
cor(training$FlyAsh, training$CompressiveStrength)
help(pca)
help("prcomp")
prcomp(training, scale=TRUE)
prcomp(CompressiveStrength ~., training, scale=TRUE)
p <- train(CompressiveStrength ~. , data = training, method = "pca")
train(CompressiveStrength ~. , data = training, method = "lm")
p <- train(CompressiveStrength ~. , data = training, method = "lm")
summary(p)
library(lubridate)
dat = read.csv("~/Downloads/gaData.csv")
str(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstrain
str(dat)
class(tstrain)
library(forecast)
help(bats)
plot(ts)
plot(tstrain)
str(tstrain)
summary(tstrain)
head(dat)
head(dat, 20)
head(dat, 100)
dat[330,]
dat[340,]
dat[350,]
dat[320,]
dat[310,]
max(dat$visitsTumblr)
mod <- bats(tstrain)
mod
summary(mod)
mod$y
mod$x
mod$Âº
mod$seasonal.periods
plot(mod)
plot(mod$lambda)
plot(mod$fitted.values)
plot(mod$damping.parameter)
plot(mod$gamma.values)
plot(mod$likelihood)
plot(mod$errors)
pred_bats <- predict(mod, testing)
class(mod)
plot(forecast(mod))
plot(forecast(mod))
lines(training, col = "red")
plot(forecast(mod))
lines(testing, col = "red")
accuracy(mod, testing)
accuracy(forecast(mod), testing)
forecast(mod)
accuracy(forecast(mod), testing)
fcast <- forecast(mod)
fcast
accuracy(fcast, testing)
fcast
testing
testing$visitsTumblr
accuracy(fcast, testing$visitsTumblr)
class(testing)
tstest <- ts(testing$visitsTumblr)
tstest
accuracy(fcast, tstest)
testing
training
View(training)
forecast(mod)
forecast(mod)
tstrain
tsting
testing
testing2 <- testing[1,]
testing2
ts.intersect(fcast,testing)
testing2 <- testing[10,]
testing2
testing2 <- testing[0:10,]
testing2
fcast
class(fcast)
fcast$series
fcast$x
fcast$upper
fcast$upper[,1]
fcast$upper[,2]
inside <- (testing2$visitsTumblr < fcast$upper[,2]) & (testing2$visitsTumblr > fcast$lower[,2])
inisde
inside
mod <- bats(tstrain)
tstrain
help("forecast")
fcast = forecast(mod, level = 95, h = dim(testing))
testing
dim(testingÃ§)
dim(testing)
fcast = forecast(mod, level = 95, h = dim(testing)[1])
fcast
plot(fcast)
lines(testing$visitsTumblr)
lines(tstest)
plot(fcast)
lines(tstest, color = 'red')
plot(fcast)
plot(fcast)
plot(fcast, testing)
plot(fcast
)
tstest
ts$start
tstest$
start
tstest$start
str(tstest)
tstest <- ts(testing$visitsTumblr, start = 366, end = 366+235)
plot(fcast)
lines(tstest)
lines(tstest, col = 'red')
plot(fcast)
lines(tstest, col = 'red')
inside <- (testing$visitsTumblr < fcast$upper[,2]) & (testing2$visitsTumblr > fcast$lower[,2])
fcast
tstest
inside <- (tstest < fcast$upper) & (tstest > fcast$lower)
inside
sum(inside)/length(inside)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(concrete)
library(e1071)
set.seed(325)
help("e1071")
svm()
help("svm")
mod <- svm(CompressiveStrength ~., training)
pred <- predict(mod, testing)
summary(mod)
mod
mod$residuals
pred
sqrt(((pred - testing$CompressiveStrength)**2)/length(pred))
sqrt((sum(pred - testing$CompressiveStrength)**2)/length(pred))
mean((pred - testing$CompressiveStrength)**2)
sqrt(mean((pred - testing$CompressiveStrength)**2))
setwd("Dropbox/kaggle/santander-value-prediction-challenge")
training <- read.csv("data/train.csv")
training <- training[,-1]
training2 <- log1p(training)
training2
library("caret")
set.seed(123)
fitControl <- trainControl(method = "cv", number = 10, allowParallel = TRUE)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
mod_gbm <- train(target ~., data = training2, method = 'gbm',
trControl = fitControl, shrinkage = 0.03)
mod_gbm <- train(target ~., data = training2, method = 'gbm',
trControl = fitControl, shrinkage = 0.1)
mod_gbm <- train(target ~., data = training2, method = 'gbm',
trControl = fitControl, shrinkage = 0.03, distribution = "gaussian")
class(training2)
str(training2)
is.factor(training2)
dm(training2)
dim(training2)
for i in range(1:dim(training2[2])) { is.factor(training2[,i])}
for (i in range(1:dim(training2[2]))) { is.factor(training2[,i])}
for (i in range(1:dim(training2)[2])) { is.factor(training2[,i])}
for (i in range(1:dim(training2)[2])) { is.character(training2[,i])}
for (i in range(1:dim(training2)[2])) { is.numeric(training2[,i])}
for (i in range(1:dim(training2)[2])) { print(is.factor(training2[,i]))}
dim(training2)[2]
range(1:4992)
range(1,4992)
c(1:4992)
for (i in c(1:dim(training2)[2])) { print(is.factor(training2[,i]))}
for (i in c(1:dim(training2)[2])) { if (is.factor(training2[,i])) {print("alarm")}}
for (i in c(1:dim(training2)[2])) { if (is.character(training2[,i])) {print("alarm")}}
for (i in c(1:dim(training2)[2])) { if (is.numeric(training2[,i])) {print("alarm")}}
stopCluster(cluster)
registerDoSEQ()
fitControl <- trainControl(method = "cv", number = 10)
mod_gbm <- train(target ~., data = training2, method = 'gbm',
trControl = fitControl, shrinkage = 0.03, distribution = "gaussian")
mod_gbm <- train(target ~., data = training2, method = 'gbm')
fitControl <- trainControl(method = "cv", number = 10)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl)
mod_gbm
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, n.trees = 1000)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, n.trees = 200)
mod_gbm <- train(target ~., data = training2, method = 'gbm')
fitControl <- trainControl(method = "cv", number = 10)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, n.trees = 200)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, shrinkage = 0.03)
fitControl <- trainControl(method = "cv", number = 10, shrinkage = 0.03)
fitControl <- trainControl(method = "cv", number = 10)
gbmGrid <- expand.grid(.n.trees = 150,
.shrinkage = 0.03)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, tuneGrid = gbmGrid)
gbmGrid <- expand.grid(.interaction.depth = 3.n.trees = 150,
.shrinkage = 0.03)
gbmGrid <- expand.grid(.interaction.depth = 3,
.n.trees = 150,
.shrinkage = 0.03)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, tuneGrid = gbmGrid)
gbmGrid <- expand.grid(.interaction.depth = 3,
.n.trees = 150,
.shrinkage = 0.03,
.n.minobsinnode = 10)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, tuneGrid = gbmGrid)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv", number = 10, allowParallel = TRUE)
gbmGrid <- expand.grid(.interaction.depth = 6,
.n.trees = 500,
.shrinkage = 0.03,
.n.minobsinnode = 10)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, tuneGrid = gbmGrid)
mod_gbm
gbmGrid <- expand.grid(.interaction.depth = 6,
.n.trees = 1000,
.shrinkage = 0.03,
.n.minobsinnode = 10)
stopCluster(cluster)
registerDoSEQ()
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
mod_gbm <- train(target ~., data = training2, method = 'gbm', trControl = fitControl, tuneGrid = gbmGrid)
mod_gbm
str(training)
training_notarget <- training[, -1]
training_pca <- prcomp(training_notarget, scale = TRUE, center = TRUE)
training_notarget == 0
